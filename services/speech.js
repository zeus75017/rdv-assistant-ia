/**
 * Service Speech-to-Text
 *
 * Note: Pour le MVP, on utilise le STT int√©gr√© de Twilio (gratuit).
 * Ce fichier est pr√©par√© pour une future int√©gration avec Whisper (OpenAI)
 * pour une meilleure pr√©cision si n√©cessaire.
 */

const OpenAI = require('openai');

// Client OpenAI pour Whisper (optionnel)
let openai = null;

if (process.env.OPENAI_API_KEY) {
  openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
  });
}

/**
 * Transcrit l'audio avec Whisper (OpenAI)
 * Utilis√© pour le streaming WebSocket si besoin de meilleure pr√©cision
 *
 * @param {Buffer} audioBuffer - Audio en format WAV ou MP3
 * @returns {string} - Texte transcrit
 */
async function transcribeWithWhisper(audioBuffer) {
  if (!openai) {
    throw new Error('OpenAI API key non configur√©e');
  }

  try {
    // Cr√©er un fichier temporaire pour l'audio
    const fs = require('fs');
    const path = require('path');
    const tempFile = path.join(__dirname, `../temp_${Date.now()}.wav`);

    fs.writeFileSync(tempFile, audioBuffer);

    const transcription = await openai.audio.transcriptions.create({
      file: fs.createReadStream(tempFile),
      model: 'whisper-1',
      language: 'fr'
    });

    // Nettoyer le fichier temporaire
    fs.unlinkSync(tempFile);

    return transcription.text;
  } catch (error) {
    console.error('Erreur Whisper:', error);
    throw error;
  }
}

/**
 * Buffer pour accumuler l'audio en streaming
 */
const audioBuffers = new Map();

/**
 * Traite l'audio en streaming (WebSocket)
 * Accumule les chunks et transcrit quand il y a assez de donn√©es
 *
 * @param {string} base64Audio - Audio encod√© en base64
 * @param {WebSocket} ws - WebSocket pour r√©pondre
 */
async function processAudioStream(base64Audio, ws) {
  // Pour le MVP, on utilise le STT de Twilio directement
  // Cette fonction est pr√©par√©e pour une future am√©lioration

  // D√©coder l'audio
  const audioChunk = Buffer.from(base64Audio, 'base64');

  // Dans une version avanc√©e, on accumulerait les chunks
  // et on les enverrait √† Whisper pour transcription
  // puis on r√©pondrait via le WebSocket

  console.log('üìä Chunk audio re√ßu:', audioChunk.length, 'bytes');
}

/**
 * D√©tecte le silence dans l'audio (pour savoir quand l'utilisateur a fini de parler)
 *
 * @param {Buffer} audioBuffer - Audio buffer
 * @returns {boolean} - True si silence d√©tect√©
 */
function detectSilence(audioBuffer) {
  // Analyse simple du volume
  let sum = 0;

  for (let i = 0; i < audioBuffer.length; i += 2) {
    const sample = audioBuffer.readInt16LE(i);
    sum += Math.abs(sample);
  }

  const average = sum / (audioBuffer.length / 2);
  const threshold = 500; // Ajuster selon le bruit de fond

  return average < threshold;
}

module.exports = {
  transcribeWithWhisper,
  processAudioStream,
  detectSilence
};
